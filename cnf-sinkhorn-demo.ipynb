{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pdb, time, math, numpy as np, gc, importlib, torch, os, cv2 as cv, ODEModel, matplotlib\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F \n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torchdiffeq import odeint_adjoint as odeint \n",
    "from geomloss import SamplesLoss\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import Utils, LearnVelTraj\n",
    "importlib.reload(Utils)\n",
    "from Utils import InputMapping, BoundingBox, ImageDataset, SaveTrajectory, ezshow, SaveTrajectory as st, MiscTransforms\n",
    "importlib.reload(ODEModel)\n",
    "from ODEModel import velocMLP, FfjordModel\n",
    "importlib.reload(LearnVelTraj);\n",
    "from LearnVelTraj import learn_vel_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH234 cycle. Jerk=.01. signedcurl=.1 curl everywhere. this is the one in the first paper sub. overspins a bit.\n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish234_signedcurl_even/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "render_reaches = [.015, .02]\n",
    "for j in range(3):\n",
    "    for r in range(len(render_reaches)):\n",
    "        render_reach = render_reaches[r]\n",
    "        st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename=\"render_reach_\"+str(render_reach)+\"_\"+str(j),  nsteps=10, dpiv=600, n=2500, reach=render_reach)\n",
    "\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=30, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH234 cycle. Jerk=.01. signedcurl=.1 average curl. not in the paper. spins the right amount.\n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish234_signedcurl/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "render_reaches = [.05]\n",
    "for j in range(10):\n",
    "    for r in range(len(render_reaches)):\n",
    "        render_reach = render_reaches[r]\n",
    "        st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename=\"render_reach_\"+str(render_reach)+\"_\"+str(j),  nsteps=10, dpiv=600, n=2500, reach=render_reach)\n",
    "\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH234 cycle. Jerk=.01.\n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish234/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "render_reaches = [.05]\n",
    "for j in range(10):\n",
    "    for r in range(len(render_reaches)):\n",
    "        render_reach = render_reaches[r]\n",
    "        st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename=\"render_reach_\"+str(render_reach)+\"_\"+str(j),  nsteps=10, dpiv=600, n=2500, reach=render_reach)\n",
    "    \n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH234: Use OT cubic splines\n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.7, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.7], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.7, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish234_OT_cubic/\"\n",
    "\n",
    "for j in range(10):\n",
    "    st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2500, savedir=outfolder, savename = 'render_OT_'+str(j))\n",
    "\n",
    "# xt_trajs_OT = st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2000, savedir=outfolder, savename = \"\")\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='cubic_OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='cubic_OT_render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=12, cycle=False, lw=2, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # horse character to horse - jerk = .01\n",
    "im1 = ImageDataset('frames/horse_charac.jpg'); \n",
    "im2 = ImageDataset('frames/horse.jpg'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "\n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horse_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "\n",
    "# render_reaches = [.04, .045]\n",
    "# render_reaches = [.02, None]\n",
    "render_reaches = [.05]\n",
    "for j in range(10):\n",
    "    for r in range(len(render_reaches)):\n",
    "        render_reach = render_reaches[r]\n",
    "        st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename=\"render_reach_\"+str(render_reach)+\"_\"+str(j),  nsteps=20, dpiv=600, n=2500, reach=render_reach)\n",
    "    st.get_OT_trajectory(keyframes, nsteps=20, n=2500, ot_type=2, savedir=outfolder, savename='render_OT_'+str(j))\n",
    "\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "# xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# horse down to horse up - jerk = .01\n",
    "im1 = ImageDataset('frames/horse1.jpg'); \n",
    "im2 = ImageDataset('frames/horse2.jpg'); \n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horseup_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "\n",
    "render_reaches = [.02, .03, .04, .05]\n",
    "for j in range(10):\n",
    "    for r in range(len(render_reaches)):\n",
    "        render_reach = render_reaches[r]\n",
    "        st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename=\"render_reach_\"+str(render_reach)+\"_\"+str(j),  nsteps=20, dpiv=600, n=2500, reach=render_reach)\n",
    "    st.get_OT_trajectory(keyframes, nsteps=20, n=2500, ot_type=2, savedir=outfolder, savename='render_OT_'+str(j))\n",
    "\n",
    "\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=2, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=2, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TRAIN halloween ish. Concatenated OT maps only.\n",
    "f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 10000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='red')\n",
    "ezshow(dat2, col='yellow')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='black')\n",
    "\n",
    "outfolder = \"results/experiment_spook_cubic_OT/\"\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "\n",
    "xt_trajs_OT = st.get_cubic_OT_trajectory(keyframes, nsteps=20, n=2000)\n",
    "\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
    "                       dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. Concatenated OT maps only.\n",
    "# # f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# # f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# # f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# # f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# # dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# # dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='yellow')\n",
    "# # ezshow(dat3, col='orange')\n",
    "# # ezshow(dat4, col='black')\n",
    "\n",
    "# # outfolder = \"results/experiment_spook_OT/\"\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# # xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=2000, ot_type=2)\n",
    "\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False)\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, keyframes=True, Nrbf = 100000, Nqvr=50, showVelocity=False,tightBB=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## TRAIN halloween ish. jerk .01, polar .1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_polar/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. jerk .01, radial .1\n",
    "# # f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# # f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# # f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# # f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# # dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# # dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='yellow')\n",
    "# # ezshow(dat3, col='orange')\n",
    "# # ezshow(dat4, col='black')\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# # model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# # outfolder = \"results/experiment_spook_radial/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# # xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "# #                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "# #                        dpiv=600, sigma=None, knn=15, cycle=False, lw=5, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: noreg. sigma=7\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 7, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_noreg_sigma7/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: noreg. sigma=5\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 5, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_noreg_sigma5/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. div 1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_div1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. rigid 2\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_rigid/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. curl on trajectory .1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_curlmean_p1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. accel = 1\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_accel_1/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN halloween ish. base: jerk=.01. accel = 5\n",
    "# f1 = ImageDataset('frames/witch.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/cat2.png',noise_std=0); \n",
    "# f3 = ImageDataset('frames/pumpkin.jpg',noise_std=0); \n",
    "# f4 = ImageDataset('frames/bat.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.3], center = [3,.25], rotate = 0),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.5, -1], center = [1.4,0], rotate = 0),0); \n",
    "# dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.5, -.5], center = [2.4,-.15], rotate = 0),0); \n",
    "# dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.7, -.5], center = [0,1], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='yellow')\n",
    "# ezshow(dat3, col='orange')\n",
    "# ezshow(dat4, col='black')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat3, dat2, dat4)).to(device));\n",
    "# model = FfjordModel(sigmac = 3, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_spook_accel_5/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # # ## TRAIN carcination. jerk=.01. seems to look fine. not really going for a point here. but it looks cool enough i guess.\n",
    "# # f1 = ImageDataset('frames/lobster.jpg',noise_std=0,thresh=.50,binary=False); \n",
    "# # f2 = ImageDataset('frames/crab.jpg',noise_std=0); \n",
    "\n",
    "# # n_inner = 10000;\n",
    "# # n_sil = 10000 - n_inner;\n",
    "# # dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1.7, -1], center = [0,0], rotate = 0),0); \n",
    "# # dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1], center = [.9,0], rotate = -np.pi/2),0); \n",
    "\n",
    "# # ezshow(dat1, col='red')\n",
    "# # ezshow(dat2, col='blue')\n",
    "# # plt.axis('equal')\n",
    "\n",
    "# # keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# # model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# # outfolder = \"results/experiment_carcinization_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "# # xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "# #                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=False, lw=0, contrast=2, Nrbf = 100000, keyframes=False, tightBB=True)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # after running rect_base and rect_slight_div, run this to get areas.\n",
    "# points = xt_trajs_1[0];\n",
    "# areas = np.zeros(points.shape[2])\n",
    "# for i in range(points.shape[2]):\n",
    "#     chull = scipy.spatial.ConvexHull(points[:,:,i])\n",
    "#     areas[i] = chull.volume\n",
    "# areas1=areas\n",
    "\n",
    "# points = xt_trajs_2[0];\n",
    "# areas = np.zeros(points.shape[2])\n",
    "# for i in range(points.shape[2]):\n",
    "#     chull = scipy.spatial.ConvexHull(points[:,:,i])\n",
    "#     areas[i] = chull.volume\n",
    "# areas2=areas\n",
    "\n",
    "# print(areas1[-1]-areas1[0]) \n",
    "# print(areas1.max()/areas1[0]) \n",
    "\n",
    "# print(areas2[-1]-areas2[0]) \n",
    "# print(areas2.max()/areas2[0]) \n",
    "\n",
    "# plt.plot(areas1/areas3[0],'r')\n",
    "# plt.plot(areas2/areas3[0],'g')\n",
    "\n",
    "# np.savetxt('results/outcache/areas1.txt', areas1)\n",
    "# np.savetxt('results/outcache/areas2.txt', areas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # ## TRAIN rectangles. KE=.1, div=1\n",
    "# n_inner = 10000;\n",
    "# dat1 = torch.rand(n_inner,2)-.5\n",
    "# dat2 = torch.rand(n_inner,2)-.5\n",
    "# dat2[:,0]*=3;dat2[:,1]/=3;\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_rects_slight_div/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)\n",
    "# xt_trajs_2 = xt_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # ## TRAIN rectangles. KE=.1, div=0\n",
    "# # optimal transport from (1,1) square to (.33,3) rectangle should result in an area increase of 33.3% at the middle of the trajectory.\n",
    "# n_inner = 10000;\n",
    "# dat1 = torch.rand(n_inner,2)-.5\n",
    "# dat2 = torch.rand(n_inner,2)-.5\n",
    "# dat2[:,0]*=3;dat2[:,1]/=3;\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_rects_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=40, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)\n",
    "# xt_trajs_1 = xt_trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # ## TRAIN bars. KE=.01, rigid=10\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_more_rigid/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN bars. KE=.01, rigid=1\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_rigid/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ## TRAIN bars. KE=.01\n",
    "# f1 = ImageDataset('frames/square.png',noise_std=0); \n",
    "# rotate = torch.tensor(.3)\n",
    "# s, c = (torch.sin(rotate), torch.cos(rotate))\n",
    "# rot = torch.stack([torch.stack([c, -s]), torch.stack([s, c])])\n",
    "\n",
    "# n_inner = 10000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, .1]),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, .1], center = [0, -.1]),0); \n",
    "# dat1 = dat1 @ rot\n",
    "# dat2 = dat2 @ rot.t()\n",
    "\n",
    "# ezshow(dat1, col='red')\n",
    "# ezshow(dat2, col='green')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_bars_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=True)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# # st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "# #                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000,keyframes=True)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_tight',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=3, contrast=3, Nrbf = 100000, keyframes=True, tightBB=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # horse character to horse - jerk = .01\n",
    "# generate points\n",
    "im1 = ImageDataset('frames/horse_charac.jpg'); \n",
    "im2 = ImageDataset('frames/horse.jpg'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d1 = im1.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d2 = im2.sample(n_inner, n_sil, center = [1, .5], scale=[-1, -1]); \n",
    "\n",
    "dat1 = torch.cat(d1,0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_horse_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=10000)\n",
    "np.savetxt(outfolder+'xt_trajs.txt', torch.cat((torch.tensor(xt_trajs[0].shape), xt_trajs[0].reshape(-1)),0))\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000)\n",
    "\n",
    "xt_trajs_OT = st.get_OT_trajectory(keyframes, nsteps=20, n=10000, ot_type=2)\n",
    "np.savetxt(outfolder+'xt_trajs_OT.txt', torch.cat((torch.tensor(xt_trajs_OT[0].shape), xt_trajs_OT[0].reshape(-1)),0))\n",
    "# st.render_2d(model, keyframes, xt_trajs_OT, savedir=outfolder, savename='OT_render',\n",
    "#                        dpiv=600, sigma=None, knn=15, cycle=False, lw=0, contrast=3, keyframes=False, Nrbf = 100000, Nqvr=1, showVelocity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BUTTERFLY->CAT->CATERPILLAR - KE = .01, radialke = .1\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_BCC_radial/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=4000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=1, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BUTTERFLY->CAT->CATERPILLAR - base. KE = .01\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_BCC_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder+'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=4000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=False, lw=1, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## GENERATE CYCLIC BUTTERFLY->CAT->CATERPILLAR. enforce completely cyclic.\n",
    "# im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "# im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "# im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "# im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "# n_inner = 7000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [1, -1.2]); \n",
    "# d1a = im1.sample(n_inner, n_sil, center = [0, .13]); \n",
    "# d1b = im1b.sample(n_inner, n_sil, center = [0, .13]); \n",
    "# d6 = im6.sample(n_inner, n_sil, center = [2, .15]); \n",
    "\n",
    "# dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "# dat2 = torch.cat(d2,0)\n",
    "# dat6 = torch.cat(d6,0)\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat6, col='magenta')\n",
    "\n",
    "# ## TRAIN CYCLIC BUTTERFLY->CAT->CATERPILLAR. .1 radial, .01 jerk\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat6, dat2, dat1)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 4, in_features=3, out_features=2, incrementalMask = True,  Tperiod = len(keyframes)-1).to(device)\n",
    "# outfolder = \"results/experiment_BCC_cyclic/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=20, cycle=True, lw=.5, contrast=3, Nrbf = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN umbrella. Jerk=.01. poor temporal consistency because of discretized ot registration.\n",
    "# f1 = ImageDataset('frames/birdflock_start.jpg',noise_std=0,thresh=.9,binary=False); \n",
    "# f2 = ImageDataset('frames/umbrella.jpg',noise_std=0,thresh=.9); \n",
    "# f3 = ImageDataset('frames/birdflock_end.jpg',noise_std=.1,thresh=1,binary=False); \n",
    "\n",
    "# # dat1 = torch.cat(f1.sample(1000, 0, scale = [1.5, -1.2], center = [-1.5, .125], rotate = 0),0); \n",
    "# # dat1 = torch.randn(1000,2); dat1[:,0]*=.5; dat1[:,1]*=.2; dat1[:,0]-=.6\n",
    "# dat2 = torch.randn(1000,2); dat2[:,0]*=.2; dat2[:,1]*=.1; dat2[:,0]-=.2; dat2[:,1]+=.1\n",
    "# dat1 = dat2.clone(); dat1[:,0]-=.5\n",
    "# dat3 = torch.cat(f2.sample(900, 100, scale = [1, -1.1], center = [.13, -.05], rotate = 0),0); \n",
    "# dat4 = torch.cat(f3.sample(1000, 0, scale = [2, -2], center = [.2, .2], rotate = 0),0); \n",
    "# dat5 = torch.randn(1000,2); dat5[:,0]*=.8; dat5[:,1]*=.8; dat5[:,1]+=.5\n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='orange')\n",
    "# ezshow(dat3, col='red')\n",
    "# ezshow(dat4, col='blue')\n",
    "# # ezshow(dat5, col='green')\n",
    "\n",
    "# # keyframes = torch.stack((dat1, dat2, dat3, dat4, dat5)).to(device);\n",
    "# keyframes = torch.stack((dat1, dat2, dat3, dat4)).to(device);\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_umbrella_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = True, lr = 1e-4, scaling = .4, normalize=False)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=100)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render_points',\n",
    "#                        dpiv=600, sigma=.01, knn=1, cycle=False, lw=.01, contrast=1, Nrbf = 0, keyframes=False, showVelocity=False, plotKeypoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, div=1, rig.1\n",
    "f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.11, .125], rotate = 0),0); \n",
    "dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.13, -.05], rotate = -np.pi*.375),0); \n",
    "dat3 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, -.2], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='blue')\n",
    "\n",
    "keyframes = torch.stack((dat1, dat2, dat3)).to(device);\n",
    "\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MMF_rigdiv/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4, normalize=False)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, \n",
    "# f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.2, .5], rotate = -np.pi/7),0); \n",
    "# dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 4, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_MF2_base/\"\n",
    "# # model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TRAIN MF. Jerk=.01\n",
    "# f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "# f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "# n_inner = 8000;\n",
    "# n_sil = 10000 - n_inner;\n",
    "# dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.11, .325], rotate = 0),0); \n",
    "# dat2 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [.13, .15], rotate = -np.pi*.375),0); \n",
    "# dat3 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "# ezshow(dat1, col='yellow')\n",
    "# ezshow(dat2, col='red')\n",
    "# ezshow(dat3, col='blue')\n",
    "\n",
    "# keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3)).to(device));\n",
    "\n",
    "# model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "# outfolder = \"results/experiment_MMF_base/\"\n",
    "# model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)\n",
    "# # model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "# xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "#                        nsteps=20, dpiv=600, n=2000)\n",
    "# st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "#                        dpiv=600, sigma=None, knn=10, cycle=True, lw=0, contrast=3, Nrbf = 100000,keyframes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## GENERATE FISH IMAGES\n",
    "f1 = ImageDataset('frames/fish1.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1.2, -1], center = [-.07, .9], rotate = -np.pi/2),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [.9, -1], center = [.9, 0], rotate = -np.pi),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [.9, -1.0], center = [0, -.9], rotate = np.pi/2),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [.95, -1.0], center = [-.9, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH1234 circle. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENDER ABOVE\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TRAIN FISH1234 circle. Jerk=.01. rigid=.1, curl-pi=.1\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle_morecurl_andrigid/\"\n",
    "model.load_state(outfolder + 'models/state_0050.tar')\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=953, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 5e-5, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RENDER ABOVE\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_circle_morecurl_andrigid/\"\n",
    "# model.load_state(outfolder + 'models/state_final.tar')\n",
    "model.load_state(outfolder + 'models/state_0050.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, rigid=2\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF2_rigid/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE MF IMAGES\n",
    "f1 = ImageDataset('frames/male.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/female.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [0, 0], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01, rigid=2\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF_rigid/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN MF. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_MF_base/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE FISH IMAGES\n",
    "f1 = ImageDataset('frames/fish1.jpg',noise_std=0); \n",
    "f2 = ImageDataset('frames/fish2.jpg',noise_std=0); \n",
    "f3 = ImageDataset('frames/fish3.jpg',noise_std=0); \n",
    "f4 = ImageDataset('frames/fish4.jpg',noise_std=0); \n",
    "\n",
    "n_inner = 8000;\n",
    "n_sil = 10000 - n_inner;\n",
    "dat1 = torch.cat(f1.sample(n_inner, n_sil, scale = [1, -1.1], center = [-.7, .6], rotate = 0),0); \n",
    "dat2 = torch.cat(f2.sample(n_inner, n_sil, scale = [1, -1.1], center = [.7, -.6], rotate = 0),0); \n",
    "dat3 = torch.cat(f3.sample(n_inner, n_sil, scale = [1, -1.1], center = [.7, .6], rotate = 0),0); \n",
    "dat4 = torch.cat(f4.sample(n_inner, n_sil, scale = [1, -1.1], center = [-.7, -.6], rotate = 0),0); \n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01, curl=3\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_min3curl/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER FISH1234. Jerk=.01, curl=3\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234_min3curl/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01, curl=1\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234_mincurl/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAIN FISH1234. Jerk=.01\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "\n",
    "model = FfjordModel(sigmac = 2, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 1, in_features=3, out_features=2, incrementalMask = True,  Tperiod = None).to(device)\n",
    "outfolder = \"results/experiment_fish1234/\"\n",
    "model, losses, separate_losses, lrs, n_subs, separate_times = learn_vel_trajectory(keyframes, n_iters = 300, stepsperbatch=50, n_subsample=300, model=model, outname=outfolder, sqrtfitloss=True, detachTZM = False, lr = 1e-4, scaling = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENDER FISH1234\n",
    "keyframes, __ = ImageDataset.normalize_samples(torch.stack((dat1, dat2, dat3, dat4)).to(device));\n",
    "model = FfjordModel(sigmac = 4, n_freq = 100, hidden_layers=3, hidden_features=512, tdiv = 2, in_features=3, out_features=2, incrementalMask = True, Tperiod=len(keyframes)-1).to(device)\n",
    "outfolder = \"results/experiment_fish1234/\"\n",
    "model.load_state(outfolder + 'models/state_final.tar')\n",
    "\n",
    "xt_trajs = st.save_trajectory_2d(model, keyframes, savedir=outfolder, savename='render',\n",
    "                       nsteps=20, dpiv=600, n=2000)\n",
    "st.render_2d(model, keyframes, xt_trajs, savedir=outfolder, savename='render',\n",
    "                       dpiv=600, sigma=None, knn=12, cycle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE BUNCH OF IMAGES\n",
    "im1 = ImageDataset('frames/butterfly.jpg'); \n",
    "im1b = ImageDataset('frames/butterflyfilled.jpg'); \n",
    "im2 = ImageDataset('frames/caterpillar.png', noise_std = .005); \n",
    "im3 = ImageDataset('frames/circle.jpeg'); \n",
    "im4 = ImageDataset('frames/baldhead.jpeg'); \n",
    "im5 = ImageDataset('frames/square.png'); \n",
    "im6 = ImageDataset('frames/cat1.png'); \n",
    "\n",
    "n_inner = 7000;\n",
    "n_sil = 10000 - n_inner;\n",
    "d2 = im2.sample(n_inner, n_sil, scale = [-1, -1], center = [0.05, -.5]); \n",
    "d1a = im1.sample(n_inner, n_sil, center = [0, 0]); \n",
    "d1b = im1b.sample(n_inner, n_sil, center = [0, 0]); \n",
    "d3 = im3.sample(n_inner, n_sil, center = [1, .5]); \n",
    "d4 = im4.sample(n_inner, n_sil, center = [1, -.5]); \n",
    "d5 = im5.sample(n_inner, n_sil, center = [1.9, .3]); \n",
    "d6 = im6.sample(n_inner, n_sil, center = [2, -.3]); \n",
    "\n",
    "dat1 = torch.cat((d1a[0], d1b[1]),0)\n",
    "dat2 = torch.cat(d2,0)\n",
    "dat3 = torch.cat(d3,0)\n",
    "dat4 = torch.cat(d4,0)\n",
    "dat5 = torch.cat(d5,0)\n",
    "dat6 = torch.cat(d6,0)\n",
    "\n",
    "ezshow(dat1, col='yellow')\n",
    "ezshow(dat2, col='red')\n",
    "ezshow(dat3, col='orange')\n",
    "ezshow(dat4, col='green')\n",
    "ezshow(dat5, col='blue')\n",
    "ezshow(dat6, col='magenta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
